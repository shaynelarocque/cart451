// Importing required modules
const express = require('express');
const bodyParser = require('body-parser');
const dotenv = require('dotenv').config();
const { MongoClient, ServerApiVersion } = require('mongodb');
const OpenAI = require('openai');

// MongoDB configuration
const uri = process.env.MONGO_URI;
const dbName = 'DigitalReflectionsCluster';
const client = new MongoClient(uri, {
  useNewUrlParser: true,
  useUnifiedTopology: true,
  serverApi: ServerApiVersion.v1
});

// Express app initialization
const app = express();
const port = 3000;
app.use(bodyParser.json());
app.use(express.static('public'));

// OpenAI configuration
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Function to analyze image with OpenAI
async function analyzeImage(imageUrl) {
  const response = await openai.chat.completions.create({
    model: "gpt-4-vision-preview",
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: "Whatâ€™s in this image? Describe the person's physical traits." },
          { type: "image_url", image_url: { "url": imageUrl } },
        ],
      },
    ],
    max_tokens: 2128,
  });

  console.log(response.choices[0]);
  return response.choices[0];
}

// Main function for generating art
async function main(userDesc1, userDesc2, userDesc3, userDesc4, userDesc5, userDesc6, userDesc7, userDesc8, selfDescription) {
  console.log("Generating...")

  const completion = await openai.chat.completions.create({
    model: 'gpt-4-1106-preview',
    response_format: { "type": "json_object" },
    messages: [
      {
        role: 'system',
        content: `You are an advanced caricaturization AI that specializes in making inferences of users based only on simple text descriptions of them, and making art of them in P5JS. Based on the following context generated by AI image captioning models of a photo of the user, generate a JSON response, containing inferences and P5JS Code.`
      },
      {
        role: 'user',
        content: `
        Context:
        1. "${userDesc1}".
        2. "${userDesc2}".
        3. "${userDesc3}".
        4. "${userDesc4}".
        5. "${userDesc5}".
        5. "${userDesc6}".
        5. "${userDesc7}".
        
        JSON Fields:
        1. "Description": A string, a combination of all the provided descriptions into a much more human readable format. [MAX 20 WORDS]
        2. "Race": A string, your best guess of what race the user could be. If a race is not provided, make one up. [ONE WORD]
        3. "Gender": A string, your best guess of what gender the user could be. If a gender is not provided, make one up and be +2SLGBTQIA Inclusive. Do not guess Bisexual just to be safe, be unafraid of being wrong. [ONE WORD]
        4. "Sexuality": A string, your best guess of what sexuality the user could be. If a sexuality is not provided, make one up. Do not say undertermined. [ONE WORD]
        5. "Location": A string, a guess of where the user's main country & city of residence is, based on the inferences. If one is not provided, make one up. [MAX 5 WORDS]
        6. "Interests": A string, a guess of what the user's potential interests are, based on the inferences. [MAX 5 WORDS]
        7. "Takeaways": A string, inferences based on the descriptions provided (e.g. "I think they are a white male with an interest in gaming from Canada") BE BOLD. BE OKAY WITH BEING WRONG. THE USERS HAVE CONSENTED TO THIS. [MAX 20 WORDS]
        8. "ArtDescription": A string, a description of the P5JS artwork which the user will see. Outline what you were going for and why. Include the above information, such as "The user is Asian, therefore..." [20 WORDS]
        9. "p5js": A string, a fully functioning 1000x1000 p5js generative artwork with no comments. Change the color of the background. Include elements that move that brings the art to life that uses MouseX and MouseY. If it helps, use advanced mathematics, grain to add detail, perlin noise, flow fields, and the principles of rorschach art to make beautiful intricate shapes, patterns, and movement. The art is colorful based on the takeaways. ABSOLUTELY NO COMMENTS. Include some design that represents the user themselves. [UNLIMITED WORDS]
        `
      }
    ],
    temperature: 1.0,
    top_p: 0.7,
    n: 1,
    stream: false,
    presence_penalty: 0,
    frequency_penalty: 0
  });

  console.log(completion.choices[0].message.content);
  return completion;
}

async function generateAndSpeakResponse(conversationDirection, lastUserMessage, lastAIMessage, newUserMessage) {
  console.log("Processing conversation and generating speech...");

  // Generate conversation response
  const completion = await openai.chat.completions.create({
    model: 'gpt-4-1106-preview',
    response_format: { "type": "json_object" },
    messages: [
      {
        role: 'system',
        content: `You are a conversational AI designed for ongoing dialogues. You consider previous messages and a given direction to steer the conversation. Your responses should be contextually relevant, engaging, and maintain the flow of conversation. Tonally, you are a tad sarcastic, surreal, and witty.`
      },
      {
        role: 'user',
        content: `Last User Message: "${lastUserMessage}"`
      },
      {
        role: 'assistant',
        content: `Last AI Message: "${lastAIMessage}"`
      },
      {
        role: 'user',
        content: `New User Message: "${newUserMessage}"`
      },
      {
        role: 'system',
        content: `Steer Conversation Towards: "${conversationDirection}"`
      }
    ],
    temperature: 0.7,
    top_p: 0.9,
    n: 1,
    stream: false,
    presence_penalty: 0.1,
    frequency_penalty: 0.1
  });

  const aiResponse = completion.choices[0].message.content.NextResponse;
  const speech = await openai.audio.speech.create({
    model: "tts-1",
    voice: "onyx",
    input: aiResponse,
  });

  const buffer = Buffer.from(await speech.arrayBuffer());
  const speechFile = 'public/speechFiles/response.mp3';
  await fs.writeFile(speechFile, buffer);
  
  console.log(`Speech file saved: ${speechFile}`);
}

// API Endpoints

// Endpoint for openai image analysis
app.post('/analyze-image', async (req, res) => {
  try {
    console.log('Received image analysis request');
    const { imageUrl } = req.body;
    const visionResponse = await analyzeImage(imageUrl);
    res.json(visionResponse);
  } catch (error) {
    console.error(error);
    res.status(500).send('Error processing image analysis.');
  }
});

// Endpoint for art generation
app.post('/generate-art', async (req, res) => {
  try {
    console.log('Received Art Generation Request');
    const { userDesc1, userDesc2, userDesc3, userDesc4, userDesc5, userDesc6, userDesc7, userDesc8, selfDescription } = req.body;
    const completion = await main(userDesc1, userDesc2, userDesc3, userDesc4, userDesc5, userDesc6, userDesc7, userDesc8, selfDescription);
    const content = completion.choices[0].message.content;

    res.type('text').send(content);
  } catch (error) {
    console.error(error);
    res.status(500).send('An error occurred on the server.');
  }
});

// Endpoint for conversation generation
app.post('/conversation', async (req, res) => {
  try {
    const { conversationDirection, lastUserMessage, lastAIMessage, newUserMessage } = req.body;
    const speechFilePath = await generateAndSpeakResponse(conversationDirection, lastUserMessage, lastAIMessage, newUserMessage);

    res.json({ speechFileUrl: `http://localhost:3000/${speechFilePath}` });
  } catch (error) {
    console.error(error);
    res.status(500).send('An error occurred');
  }
});

// Endpoint to save artData
app.post('/save-artdata', async (req, res) => {
  try {
    await client.connect();
    const database = client.db(dbName);
    const artData = database.collection('artData');

    // Insert the artData received from the client
    const result = await artData.insertOne(req.body);
    res.status(200).send(`ArtData saved with id: ${result.insertedId}`);
  } catch (error) {
    console.error(error);
    res.status(500).send('Error saving art data to database.');
  } finally {
    await client.close();
  }
});

// Server initialization
app.listen(port, () => {
  console.log(`Server listening at http://localhost:${port}`);
});